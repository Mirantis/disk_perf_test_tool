#  ------------------------------------    CONFIGS   -------------------------------------------------------------------
#openstack:
#    skip_preparation: false
#    openrc: /home/koder/workspace/scale_openrc
#    insecure: true
#    openrc: ENV
#    openrc:
#        OS_USERNAME: USER
#        OS_PASSWORD: PASSWD
#        OS_TENANT_NAME: KEY_FILE
#        OS_AUTH_URL: URL
#        OS_INSECURE: OPTIONAL
#    vms:
#        - "USERNAME@VM_NAME_PREFIX"
#
#ceph:
#    cluster: ceph   << Optional
#    config: PATH    << Optional
#    keyfile: PATH   << Optional
#    key: KEY   << not supported for now
#    root_node: NODE_NAME
#
#
# nodes: - map of explicit nodes URLS to node roles
# in format
#    USERNAME[:PASSWD]@VM_NAME_PREFIX[::KEY_FILE] or localhost: role1, role2, role3....

collect_info: true
var_dir_root: /tmp/perf_tests
settings_dir: ~/.wally
connect_timeout: 30
max_time_diff_ms: 5000
rpc_log_level: DEBUG
include: logging.yaml
default_test_local_folder: "/tmp/wally_{name}_{uuid}"
keep_raw_files: false  # don't change this value, keep is not supported atm
download_rpc_logs: true

vm_configs:
    keypair_file_private: wally_vm_key_perf3.pem
    keypair_file_public: wally_vm_key_perf3.pub
    keypair_name: wally_vm_key

    wally_1024:
        image:
            name: wally_ubuntu
            user: ubuntu
            url: https://cloud-images.ubuntu.com/trusty/current/trusty-server-cloudimg-amd64-disk1.img

        flavor:
            name: wally_1024
            hdd_size: 100
            ram_size: 1024
            cpu_count: 2

        vol_sz: 100
        name_templ: wally-{group}-{id}
        aa_group_name: wally-aa-{0}
        security_group: wally_ssh_to_everyone


ceph_opts: nodeep-scrub, noscrub
#-----------------------------------------    STEPS   ------------------------------------------------------------------
# discover: a,b,c,... - comma separated list of clusters to discover. May be ommited
#    List may contains - ceph, openstack, fuel
#    Also - ignore_errors - mean to ignore errors during dicovery
#           metadata - mean to discrover cluster metadata only, but not nodes
# spawn: ...
# connect: ...
# sensors: ...
# test: ...

sensors:
   online: true
   roles_mapping:
       testnode: system-cpu, block-io, net-io
       ceph-osd:
            system-cpu: "*"
            block-io: "*"
            net-io: "*"
            ceph:
              sources: [historic]
              osds: all
       compute:
            system-cpu: "*"
            block-io: "sd*"
            net-io: "*"
   cluster: ceph-pools-io, ceph-pgs-io

#----------------------------------   TEST PROFILES --------------------------------------------------------------------
profiles:
    spawn:
        OS_1_to_1:
            openstack:
                count: "=1"
                cfg_name: wally_1024
                network_zone_name: net04
                flt_ip_pool: net04_ext
                skip_preparation: true

    test:
        ceph_vdb:
            - io:
                load: ceph
                params:
                    FILENAME: /dev/vdb
                    FILESIZE: AUTO

        cinder_iscsi_vdb:
            - io:
                load: cinder_iscsi
                params:
                    FILENAME: /dev/vdb
                    FILESIZE: AUTO

        nova_io:
            - io:
                load: hdd
                params:
                    FILENAME: /opt/test.bin
                    FILESIZE: AUTO

    openstack_ceph: OS_1_to_1 + ceph_vdb
    openstack_cinder: OS_1_to_1 + ceph_iscsi_vdb
    openstack_nova: OS_1_to_1 + nova_io


default_dev_roles:
    - role=testnode:
        - type=cpu: client_cpu
        - type=block: client_disk
        - type=eth: client_net
        - type=weth: client_net

    - role=storage:
        - type=cpu: storage_cpu
        - type=block: storage_disk
        - type=eth: storage_net
        - type=weth: storage_net

    - role=compute:
        - type=cpu: compute_cpu
        - type=block: compute_disk
        - type=eth: compute_net
        - type=weth: compute_net
